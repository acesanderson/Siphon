# AI Integration in Software Engineering: A Panel Discussion on Practical Adoption and Real-World Applications

This panel discussion from Dash explores how software engineers can practically integrate AI into their workflows, moving beyond the hype to understand real applications, challenges, and organizational adoption strategies.

## Panel Introduction and Current State of AI

The session, led by Jason, a Staff Technical Advocate at Datadog, brought together experts from different aspects of the AI integration journey. The panelists included:

- **Rema**, a data scientist at Datadog working on Watchdog and detecting faulty code deployments
- **Randy Defauw**, a solution architect at AWS with a background spanning autonomous vehicles research and data science
- **Sam Torio**, from Datadog's information security department, focusing on secure AI tool implementation
- **Skyler Graa**, working with product and engineering at Smartsheet

When distinguishing between AI hype and real potential, Skyler noted that much skepticism stems from the 2017-2018 chatbot hype. He emphasized that measuring real value comes from looking at tangible outcomes and outputs rather than just promises.

Randy observed real market impacts, citing a significant drop in software engineering job openings since the advent of ChatGPT 3.5. However, he believes AI will make good engineers better at all aspects of their work—not just writing code, but systems analysis, documentation, and test cases.

Rema stressed the importance of basic AI literacy: "I wouldn't expect everyone to start to drop everything and start learning AI and how to train models, but I think everyone could get some basic concepts of how our models are trained, what to expect from them. This will allow us to demystify a lot of the concepts and allow us to have good expectations of what are the current limitations today."

## Who Should Adopt AI and Skill Development

The panel agreed that AI tools are beneficial for engineers at all levels, though in different ways. Randy suggested that while everyone should use these tools, really good engineers can probably be more efficient with them. He noted that entry-level engineers might benefit from using AI to navigate new codebases more quickly than traditional methods.

Skyler, speaking from his senior principal software engineer perspective, disagreed with studies suggesting senior engineers benefit less. He explained that the more technical depth you can bring to your prompts, the more rich and useful results you'll get.

However, Rema raised important concerns about junior engineers: "I'm mostly worried about junior engineers because if we're talking about generative AI, it currently offers a lot of breadth of information but not a lot of depth. It can currently solve easy tasks and not complex ones in the software engineering world." She worried this might impact their incentive to learn core software engineering concepts and build the problem-solving muscles essential for handling complex issues later in their careers.

The panel identified several critical skills for effective AI adoption:

- **Code reading and review skills** became paramount, as Sam noted: "The most important skill is actually not being able to write code anymore but being able to read code and understand it."
- **Defining success criteria** for AI output, especially important for generative AI where there's no standardized way to judge quality
- **Prompt engineering skills** to get better, more targeted results from AI systems
- **Maintaining core engineering competencies** to effectively review and validate AI-generated solutions

## Staying Current with AI Developments

Keeping up with rapidly evolving AI capabilities presents challenges for busy engineers. The panel offered several practical strategies:

Skyler recommended starting with mobile AI applications for daily use: "Get rid of some of those decisions that you're having to make. I've started using it even for dates with my girlfriend... By doing this, I'm really starting to gain just a better understanding of when to actually be using this."

Sam focused on problem-driven adoption: "Focusing more on the problems that you're actually trying to solve right—a solution is only as good as the problems that it's facing. As you encounter problems, understanding whether or not that's something that generative AI can help you with is probably the right approach."

Randy suggested finding tasks you dislike: "The things I really hate doing—like when I write an email, I tend to be very brusque and to the point... Sometimes I'll use generative AI to make this more senior management friendly."

Rema recommended curating information sources: "My strategy has been to really filter out all the content that I get. I try to follow AI experts that are very close to most important contributions in the field and I listen to a lot of podcasts summarizing all the AI news from last week."

## Organizational Adoption Strategies

Moving from individual to organizational adoption requires addressing security, compliance, and change management challenges. Sam emphasized the importance of creating secure pathways: "The most effective way that organizations can encourage the adoption of these tools is to make sure that there is a happy path forward and guard rails in place for your developers to do so."

Organizations need to balance innovation with security, especially when dealing with customer data. Randy's team at AWS had to solve for information security concerns systematically when analyzing customer documents, but found success in rapid prototyping and demo development.

The panel identified several organizational success factors:

- **Executive support and clear policies** around AI tool usage
- **Security frameworks** that enable rather than block AI adoption
- **Education and training** on appropriate use cases and limitations
- **Active listening** to engineer concerns and feedback about tool effectiveness
- **Focus on augmentation** rather than replacement of human capabilities

## Measuring Success and Impact

Measuring AI's impact on engineering productivity proves challenging, as it ties into the broader difficulty of measuring software team effectiveness. The panel acknowledged that traditional metrics like story points or defect rates might not capture AI's true value.

Skyler suggested tracking curiosity and courage as leading indicators: "More than ever we have to have courage to actually get past some of these existential threats... I would say knowing, gauging what that sort of curiosity meter is and how engineers are diving in and using it."

They recommended starting with concrete input metrics—usage frequency, response acceptance rates—before progressing to more complex output measurements like feature delivery speed improvements.

Randy emphasized the importance of understanding the opportunity cost: "Time has an opportunity cost of what else you can be doing, and I think there's a lot of value in the new things that humans can focus on while the computers do the hard work."

## Key Challenges and Considerations

The discussion revealed several ongoing challenges:

**Model limitations**: Generative AI models "do not plan, they do not reason—they make good guesses given all the data that they were trained on," as Rema explained. This requires managing expectations and maintaining fact-checking practices.

**Context management**: Long-running conversations with AI models can degrade performance, requiring strategies like starting fresh sessions or summarizing context periodically.

**Training data issues**: Older programming languages or outdated practices in training data can lead to suboptimal code suggestions.

**Balancing automation with learning**: Organizations must find ways to leverage AI efficiency while ensuring engineers continue developing critical thinking and problem-solving skills.

The panel concluded that we're in a transitional period where the role of software engineers is evolving. While coding may become less central to the job, the need for technical depth, soft skills, and the ability to integrate between different systems and stakeholders will become increasingly important. Success will depend on thoughtful adoption that enhances human capabilities rather than simply replacing them.
